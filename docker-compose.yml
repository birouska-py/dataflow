services:

  # SOURCE
  # DATABASE - RELACIONAL
  postgres-df:
    container_name: postgres-df
    hostname: postgres-df
    image: postgres:${POSTGRES_VERSION}
    #image: "postgres:latest"
    #image: quay.io/debezium/example-postgres:2.1
    #image: debezium/postgres:16
    networks:
      - dataflow_network
    #user: "root"
    environment:
      POSTGRES_USER: "postgres"
      POSTGRES_PASSWORD: "postgres"
      POSTGRES_DB: dataflow
      PGDATA: "/data/postgres"
    volumes:
       - ~/docker_files/volumes/dataflow/postgresql:/data/postgres
       - ./utils/scripts/postgres/db_dataflow.sql:/docker-entrypoint-initdb.d/db_dataflow.sql
    ports:
      - "5432:5432"
    command:
       - "postgres"
       - "-c"
       - "wal_level=logical"
       - "-c"
       - "max_replication_slots=4"
       - "-c"
       - "max_wal_senders=4"

  #ORCHESTRATION   

  #### STREAMING 
  kafka-broker-df:
    image: docker.io/bitnami/kafka:${KAFKA_VERSION}
    container_name: kafka-broker-df
    hostname: kafka-broker-df
    user: root
    ports:
      - "9092:9092"
      - "9101:9101"
    networks:
      - dataflow_network
    environment:
      # KRaft settings
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_JMX_PORT=9101
      - KAFKA_CFG_JMX_HOSTNAME=kafka-broker-df 
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka-broker-df:29093
      - KAFKA_KRAFT_CLUSTER_ID=kafka-broker-df
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_CFG_LISTENERS=INTERNAL://kafka-broker-df:29092,CONTROLLER://kafka-broker-df:29093,EXTERNAL://0.0.0.0:9092
      - KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://kafka-broker-df:29092,EXTERNAL://kafka-broker-df:9092
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=INTERNAL
      #- KAFKA_CFG_GROUP_INITIAL_REBALANCE_DELAY_MS= 0
      - KAFKA_CFG_NUM_PARTITIONS= 3
      #- KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR= 3
      #- KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR= 3
    volumes:
      - '~/docker_files/volumes/dataflow/kafka:/bitnami/kafka'

  schema-registry-df:
    image: docker.io/bitnami/schema-registry:${SCHEMA_REGISTRY_VERSION}
    container_name: schema-registry-df
    hostname: schema-registry-df
    ports:
      - "8081:8081"
    networks:
      - dataflow_network
    environment:
      - SCHEMA_REGISTRY_HOST_NAME=schema-registry
      - SCHEMA_REGISTRY_LISTENERS=http://0.0.0.0:8081
      - SCHEMA_REGISTRY_KAFKA_BROKERS=PLAINTEXT://kafka-broker-df:29092
    depends_on:
      kafka-broker-df:
        condition: service_started

  # KAFKA CONNECT
  kafka-connect-df:
    image: ${DOCKER_HUB_ACCOUNT}/kafka-connect-debezium:${DEBEZIUM_CONTAINER_VERSION}
    container_name: kafka-connect-df
    hostname: kafka-connect-df
    networks:
      - dataflow_network
    ports:
      - 8083:8083
    depends_on:      
      - kafka-broker-df      
    environment:
    #- KAFKA_LOG4J_OPTS=-Dlog4j.configuration=file:/opt/kafka/config/connect-log4j.properties
    - KAFKA_CONNECT_BOOTSTRAP_SERVERS=kafka-broker-df:29092
    - |
        KAFKA_CONNECT_CONFIGURATION=
        key.converter=org.apache.kafka.connect.json.JsonConverter
        value.converter=org.apache.kafka.connect.json.JsonConverter
        key.converter.schemas.enable=false
        value.converter.schemas.enable=false
        group.id=connect
        offset.storage.topic=connect-offsets
        offset.storage.replication.factor=1
        config.storage.topic=connect-configs
        config.storage.replication.factor=1
        status.storage.topic=connect-status
        status.storage.replication.factor=1  
        CONNECT_REST_ADVERTISED_HOST_NAME: 'kafka-connect-df'    
    volumes:
       - ./utils/configs/connectors:/etc/kafka-connect/connectors   
       - ./utils/scripts/kafka-connect:/scripts  
    command: /scripts/entrypoint.sh createConnectors #parameter to create connector automatically
    #command: /scripts/entrypoint.sh # need create connectors manually
        
  redpanda-console-df:
    container_name: redpanda-console-df
    hostname: redpanda-console-df
    image: docker.redpanda.com/redpandadata/console:${REDPANDA_VERSION}
    restart: unless-stopped
    networks:
      - dataflow_network
    entrypoint: /bin/sh
    command: -c 'echo "$$CONSOLE_CONFIG_FILE" > /tmp/config.yml; /app/console'
    environment:
      CONFIG_FILEPATH: /tmp/config.yml
      CONSOLE_CONFIG_FILE: |
        kafka:
          brokers: ["kafka-broker-df:9092"]
        schemaRegistry:
          enabled: true
          urls: ["http://schema-registry-df:8081"]
        kafkaConnect:
          enabled: true
          clusters:
            - name: kafka-connect-df # Required field, will be used as identifier in the frontend
              url: http://kafka-connect-df:8083
              tls:
                enabled: false # Trusted certs are still allowed by default
             
    ports:
      - "8080:8080"
    depends_on:
      kafka-broker-df:
        condition: service_started
      # schema-registry-df:
      #   condition: service_started
      # kafka-connect-df:
      #   condition: service_started

  #SINK

  #DATA LAKE
  minio-df:
    image: minio/minio:${MINIO_VERSION}
    container_name: minio-df
    networks:
          - dataflow_network
    entrypoint: sh
    command:   '-c ''mkdir -p /minio_data/raw && mkdir -p /minio_data/trusted && minio server /minio_data --console-address ":9001"'''
    ports:
      - "9050:9000"
      - "9051:9001"
    hostname: minio-df
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - ~/docker_files/volumes/dataflow/minio/data:/data
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 5s
      timeout: 5s
      retries: 5

  # DATABASE - NOSQL
  mongo-df:
    image: mongo:${MONGODB_VERSION}
    container_name: mongodb-df
    hostname: mongodb-df
    networks:
      - dataflow_network
    ports:
      - 27017:27017
    volumes:
       - ~/docker_files/volumes/dataflow/mongodb:/data/db
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: password

  mongo-express-df:
    image: mongo-express:latest
    container_name: mongo-express-df
    hostname: mongo-express-df
    networks:
      - dataflow_network
    ports:
      - 8091:8081
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: root
      ME_CONFIG_MONGODB_ADMINPASSWORD: password
      ME_CONFIG_MONGODB_URL: mongodb://root:password@mongodb-df:27017/
  
networks:
  dataflow_network:
    name: dataflow-network
    driver: bridge

